### 一、Mysql锁分类：全局锁、表级锁、行锁  
#### 1.1 全局锁  
> 加全局锁命令(FTWRL)：flush tables with read lock  
> FTWRL命令执行效果：使整库完全处于只读状态。  
> 典型使用场景：做全库逻辑备份。（即：先加FTWRL，然后将整库每个表select出来存成文本）  
> 解锁方式：1. 连接断开自动解锁；  2.unlock tables;命令解锁  

> 实现全库逻辑备份都两种方式：  
> - 使用全局锁（FTWRL）--加锁读  
>> 使用全局锁做全库逻辑备份的潜在风险：  
>> 1. 如果在主库上备份，那么主库在备份期间都不能执行更新，业务基本上就得停摆。  
>> 2. 如果在从库上备份，那么从库在备份期间就不能执行从主库同步过来都binlog，会导致主从延迟。  
> - 使用官方自带都逻辑备份工具mysqldump  --MVCC一致性读：  
>> mysqldump -hlocalhost -uroot -P3306 -p --single-transaction --default-character-set=utf8 db > /etc/mysql/tmpdump002.sql  
>> ps：mysqldump --single-transaction做全库备份有两个要求：1.目标库中所有表必须使用支持事务引擎（eg.Innodb）；2.数据库隔离级别必须设定为rr  

使全库进入只读状态的两种方式：  
- FTWRL全局锁方式  
- set global readonly=true方式  
> ps：做全库备份时采用FTWRL加全局锁而不采用设置readonly的原因是：  
> - 在有些系统中，readonly的值会被用来做其它逻辑，比如用来判断一个库是主库还是从库。因此，改global变量的方式影响面更大，故不建议使用。  
> - 在异常处理机制上有差异。如果执行FTWRL命令加锁后，由于客户端发生异常而断开，那么Mysql会自动释放这个全局锁，整个库回到可以正常更新的状态。
> 而将整库设置为readonly后，如果客户端发生异常，（除其它手段介入将这个global变量重置回来，否则）数据库会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。  
> - 还有一点，readonly设置对super权限无效。即：它无法限制super权限对写行为。  


#### 1.2 表级锁  
- 表锁  
  > 加表锁：lock tables t1 read, t2 write;  
  >> 经验证（环境：mysql8.0）：加表锁后，限制其它线程对t1、t2两表的操作--只能读t1，读写t2阻塞，但可以操作其它未加表锁的表；
  >> 还限制当前已获得表锁线程，只能操作这两张表--只能读t1，读写t2，不能操作其它任何没获得表锁读表。
  > 解除表锁：unlock tables;  
  > 
- 元数据锁（meta data lock， MDL）  
> 在Mysql5.5版本引入，MDL锁不需要显示使用，在访问一个表的时候会自动加上，自动加锁规则：  
> - 当对一个表做CRUD时，加MDL读锁。  
> - 当要对表做结构变更对时候，加MDL写锁。  
>> ps：读锁之间不互斥，所以，多个线程可以同时对一张表做CRUD。  
>>  读写锁之间、写锁之间互斥，用来保证变更表结构操作的安全性。  

> MDL锁有个等待线程的（优先）队列机制，当在某一个表上发上MDL锁等待时，所有等待线程会入队且MDL写锁等待线程优先插队拍到队首。  
>> 所以可能会导致：只是加个字段，结果整个库就挂了的现象。（比如在执行修改表结构命令时，发现有个长事务正在读写该表数据，此时加在该表上的
>> MDL读锁会持续到该长事务提交才会释放，则该长事务期间，修改表结构语句线程处于MDL写锁等待状态，位于等待队列的队首。此后欲对该表做CRUD线程要加MDL读锁，
>> 但是排在等待队列中MDL写锁线程后，被阻塞，所有后续线程都无法读取该表）  
>> 这个问题有两个解决方案： 
>> 1. 解决长事务（事务不提交，MDL锁就不会释放）：避开长事务执行，或kill掉长事务。通过"select * from information_schema.innodb_trx\G;"查询当前执行中的事务，
>> 可以通过"kill connection $thread_id"来kill掉事务。  
>> 2. （超时放弃思想）在alter table语句里设置等待时间。超时拿不到MDL写锁就先放弃（不阻塞后续其它对表对CRUD操作），之后开发人员或者DBA再通过重试命令重复这个过程。  
>> ps：目前暂无命令支持这个操作。  

#### 1.3 行锁  
Mysql中行锁是由引擎层各自实现的。eg. Innodb支持行锁，MySIAM不支持行锁。  
##### 两阶段锁协议（侧重于约束"写锁"）  
> 两阶段锁协议：分为加锁阶段与解锁阶段，所有的lock都在unlock之后。在Innodb中，行锁是在需要的时候才加上，但并不是不需要了就立即释放，而是要等到事务结束时才释放。
> 即：加锁阶段"需要才加"，解锁阶段"事务提交才解"。  
>> 怎样最大限度地减少事务之间的锁等待，提升并发度？  
>> 根据两阶段锁协议，如果事务中需要锁多行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。  

### 二、死锁与死锁检测  
#### 2.1 死锁  
> 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待其它线程释放资源时，就会导致这几个线程都进入无限等待状态，称为"死锁"。  
>> 当出现死锁后，有两种打破死锁的策略：  
>>  1. 直接进入等待，直到超时。innodb中锁超时时间可以通过innodb_lock_wait_timeout参数设置，默认50s。  
>>  2. 发起死锁检测。发现死锁后，主动回滚死锁链条中都某一个事务，让其它事务得以进行。  
>> 将参数innodb_deadlock_detect设置为on，表示开启死锁检测逻辑。    
>> 正常情况下，我们都是采用第二中策略，主动发起死锁检测，而且Innodb的innodb_deadlock_detect默认值本身就是on。
>> 主动死锁检测在发生死锁的时候，能够快速发现并进行处理，但是它也有额外的负担。（类似于悲观锁）这是由下面提到的死锁检测的机制决定的。  

#### 2.2 死锁检测
> 死锁检测机制：  
> 每当一个事务被锁的时候（可能是死锁，也可能单纯的就是锁等待而不是循环依赖等待），都要判断会不会由于自己的加入导致了死锁，
> 这是一个时间复杂度为O(n)的操作，如果有多个线程被锁住，那每一个都重复O(n)的操作，那总的时间复杂度就是O(n^2)。  
> 最终检测结果可能是没有死锁，但是这期间却消耗了大量的CPU资源，造成CPU的利用率很高。  

如何解决"热点行记录"更新导致的性能问题呢？（ps：这里的"热点行记录"指多线程并发修改记录行。）  
> 1. 临时关闭死锁检测。这中方式可能会出现大量的业务超时，这是业务有损的。  
> 2. 不关闭死锁检测，转而在数据库服务端控制业务并发度。  
     > 基本思路是：对于相同行的更新，在进入引擎之前排队。这样，在innodb引擎内部就不会有大量的死锁检测工作了。  
>> - 可以在数据库中间件层实现。  
>> - 可以直接修改数据库源码实现。  
>> - 也可以从业务逻辑设计上实现。（考虑将一行改成逻辑上的多行来减少锁冲突。--这个思路有点儿ConcurrentHashMap的设计思想）



Chapter 6/7